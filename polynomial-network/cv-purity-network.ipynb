{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purity Network\n",
    "Quantum Neural Network (QNN) that compute the purity of a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import strawberryfields as sf\n",
    "from strawberryfields.ops import *\n",
    "\n",
    "from cv_state_preparation import state_preparation_network, layer, Interferometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = \"data/cv/purity/one_qumode/cutoff_5/\"\n",
    "\n",
    "n_qumodes_rho = 1\n",
    "n_qumodes_psi = n_qumodes_rho * 2 # for purification\n",
    "n_qumodes_pn = n_qumodes_rho * 2 # input: [ρ, ρ]\n",
    "n_qumodes_total = n_qumodes_psi * 2\n",
    "# modes_meas = [0,2]\n",
    "modes_meas = [0]\n",
    "\n",
    "cutoff = 5\n",
    "size_hilbert = cutoff**n_qumodes_rho\n",
    "\n",
    "ratio_train = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers_sp = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purity Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers_pn = 1\n",
    "batch_size_pn = 16\n",
    "\n",
    "passive_std = 0.1\n",
    "active_std = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.load(os.path.join(data_folder, \"rhos.npy\"))\n",
    "purities = np.load(os.path.join(data_folder, \"purities.npy\"))\n",
    "list_params = np.load(os.path.join(data_folder, \"list_params.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(rhos)\n",
    "n_samples_train = int(ratio_train*n_samples)\n",
    "n_samples_test = n_samples - n_samples_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_idx = np.random.choice(n_samples, size=n_samples, replace=False)\n",
    "rhos = rhos[samples_idx]\n",
    "purities = purities[samples_idx]\n",
    "list_params = list_params[samples_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "X_train = list_params[:n_samples_train]\n",
    "X_test = list_params[n_samples_train:]\n",
    "\n",
    "Y_train = purities[:n_samples_train]\n",
    "Y_test = purities[n_samples_train:]\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State network\n",
    "The parameters of the first network are the actual input of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# squeeze gate\n",
    "sp_sq_r = tf.placeholder(tf.float32, [n_layers_sp, n_qumodes_psi], name=\"sp_sq_r\")\n",
    "sp_sq_phi = tf.placeholder(tf.float32, [n_layers_sp, n_qumodes_psi], name=\"sp_sq_phi\")\n",
    "\n",
    "# displacement gate\n",
    "sp_d_r = tf.placeholder(tf.float32, [n_layers_sp, n_qumodes_psi], name=\"sp_d_r\")\n",
    "sp_d_phi = tf.placeholder(tf.float32, [n_layers_sp, n_qumodes_psi], name=\"sp_d_phi\")\n",
    "\n",
    "# interferometer\n",
    "sp_inter_theta = tf.placeholder(tf.float32, [n_layers_sp*2, int(n_qumodes_psi*(n_qumodes_psi-1)/2)], name=\"sp_inter_theta\")\n",
    "sp_inter_phi = tf.placeholder(tf.float32, [n_layers_sp*2, int(n_qumodes_psi*(n_qumodes_psi-1)/2)], name=\"sp_inter_phi\")\n",
    "sp_inter_rphi = tf.placeholder(tf.float32, [n_layers_sp*2, n_qumodes_psi-1], name=\"sp_inter_rphi\")\n",
    "\n",
    "# kerr gate\n",
    "sp_kappa = tf.placeholder(tf.float32, [n_layers_sp, n_qumodes_psi], name=\"sp_kappa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_params = [sp_sq_r, sp_sq_phi, sp_d_r, sp_d_phi, sp_inter_theta, sp_inter_phi, sp_inter_rphi, sp_kappa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feed_dict(params):\n",
    "    return {sp_sq_r: np.array(list(params[0])),\n",
    "            sp_sq_phi: np.array(list(params[1])),\n",
    "            sp_d_r: np.array(list(params[2])),\n",
    "            sp_d_phi: np.array(list(params[3])),\n",
    "            sp_inter_theta: np.array(list(params[4])),\n",
    "            sp_inter_phi: np.array(list(params[5])),\n",
    "            sp_inter_rphi: np.array(list(params[6])),\n",
    "            sp_kappa: np.array(list(params[7]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purity network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purity_input = tf.placeholder(tf.float32, name=\"purity\")\n",
    "lr_placeholder = tf.placeholder(tf.float32, name=\"lr_placeholder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "\n",
    "# squeeze gate\n",
    "pn_sq_r = tf.Variable(tf.random_normal(shape=[n_layers_pn, n_qumodes_pn], stddev=active_std))\n",
    "pn_sq_phi = tf.Variable(tf.random_normal(shape=[n_layers_pn, n_qumodes_pn], stddev=passive_std))\n",
    "\n",
    "# displacement gate\n",
    "pn_d_r = tf.Variable(tf.random_normal(shape=[n_layers_pn, n_qumodes_pn], stddev=active_std))\n",
    "pn_d_phi = tf.Variable(tf.random_normal(shape=[n_layers_pn, n_qumodes_pn], stddev=passive_std))\n",
    "\n",
    "# interferometer\n",
    "pn_inter_theta = tf.Variable(tf.random_normal(shape=[n_layers_pn*2, int(n_qumodes_pn*(n_qumodes_pn-1)/2)], stddev=passive_std))\n",
    "pn_inter_phi = tf.Variable(tf.random_normal(shape=[n_layers_pn*2, int(n_qumodes_pn*(n_qumodes_pn-1)/2)], stddev=passive_std))\n",
    "pn_inter_rphi = tf.Variable(tf.random_normal(shape=[n_layers_pn*2, n_qumodes_pn-1], stddev=passive_std))\n",
    "\n",
    "# kerr gate\n",
    "# pn_kappa = tf.Variable(tf.random_normal(shape=[n_layers_pn, n_qumodes_pn*2], stddev=active_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pn_params = [pn_sq_r, pn_sq_phi, pn_d_r, pn_d_phi, pn_inter_theta, pn_inter_phi, pn_inter_rphi, pn_kappa]\n",
    "pn_params = [pn_sq_r, pn_sq_phi, pn_d_r, pn_d_phi, pn_inter_theta, pn_inter_phi, pn_inter_rphi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_gaussian(i, q, params):\n",
    "    sq_r, sq_phi, d_r, d_phi, inter_theta, inter_phi, inter_rphi = tuple(params)\n",
    "\n",
    "    Interferometer(inter_theta[2*i], inter_phi[2*i], inter_rphi[2*i], q)\n",
    "    \n",
    "    for j in range(len(q)):\n",
    "        Sgate(sq_r[i,j], sq_phi[i,j]) | q[j]\n",
    "        \n",
    "    Interferometer(inter_theta[2*i+1], inter_phi[2*i+1], inter_rphi[2*i+1], q)\n",
    "    \n",
    "    for j in range(len(q)):\n",
    "        Dgate(d_r[i,j], d_phi[i,j]) | q[j]\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purification_network(q, n_layers, params):\n",
    "    # First layers with same size\n",
    "    n_qumodes = len(q)\n",
    "\n",
    "    for i in range(n_layers_pn - (n_qumodes-2)): # same-size layers\n",
    "        layer_gaussian(i, q, params)\n",
    "        \n",
    "    # Progressive size reduction for the last layers\n",
    "    for i in range(n_qumodes-2):\n",
    "#         MeasureFock(select=0) | q[i]\n",
    "        l = i+(n_layers_pn - (n_qumodes-2))\n",
    "        layer_gaussian(l, q[i+1:], params)\n",
    "        \n",
    "    # Measurement of the second-to-last qumode.\n",
    "#     MeasureFock(select=0) | q[n_qumodes-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State preparation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def batched_Interferometer(theta, phi, rphi, q):\n",
    "# \t# parameterised interferometer acting on N qumodes\n",
    "#     # theta is a list of length N(N-1)/2\n",
    "#     # phi is a list of length N(N-1)/2\n",
    "#     # rphi is a list of length N-1\n",
    "# \t# q is the list of qumodes the interferometer is to be applied to\n",
    "#     N = len(q)\n",
    "\n",
    "#     if N == 1:\n",
    "#         # the interferometer is a single rotation\n",
    "#         Rgate(rphi[:,0:1]) | q[0]\n",
    "#         return\n",
    "\n",
    "#     n = 0 # keep track of free parameters\n",
    "\n",
    "#     # Apply the Clements beamsplitter array\n",
    "#     # The array depth is N\n",
    "#     for l in range(N):\n",
    "#         for k, (q1, q2) in enumerate(zip(q[:-1], q[1:])):\n",
    "#             #skip even or odd pairs depending on layer\n",
    "#             if (l+k)%2 != 1:\n",
    "#                 BSgate(theta[:,n:n+1], phi[:,n:n+1]) | (q1, q2)\n",
    "#                 n += 1\n",
    "\n",
    "#     # apply the final local phase shifts to all modes except the last one\n",
    "#     for i in range(len(q)-1):\n",
    "#         Rgate(rphi[:,i:i+1]) | q[i]\n",
    "\n",
    "# def batched_layer(i, q, params):\n",
    "#     sq_r, sq_phi, d_r, d_phi, inter_theta, inter_phi, inter_rphi, kappa = tuple(params)\n",
    "\n",
    "#     batched_Interferometer(inter_theta[:,2*i], inter_phi[:,2*i], inter_rphi[:,2*i], q)\n",
    "    \n",
    "#     for j in range(len(q)):\n",
    "#         Sgate(sq_r[:,i,j:j+1], sq_phi[:,i,j:j+1]) | q[j]\n",
    "        \n",
    "#     batched_Interferometer(inter_theta[:,2*i+1], inter_phi[:,2*i+1], inter_rphi[:,2*i+1], q)\n",
    "    \n",
    "#     for j in range(len(q)):\n",
    "#         Dgate(d_r[:,i,j:j+1], d_phi[:,i,j:j+1]) | q[j]\n",
    "        \n",
    "#     for j in range(len(q)):\n",
    "#         Kgate(kappa[:,i,j:j+1]) | q[j]\n",
    "\n",
    "#     return q\n",
    "\n",
    "# def batched_state_preparation_network(q, n_layers, parameters):\n",
    "#     for i in range(n_layers):\n",
    "#         batched_layer(i, q, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cov(state):\n",
    "    psi = state.ket(modes=modes_meas)\n",
    "    n = tf.cast(tf.range(cutoff), tf.float32)\n",
    "    eye = tf.convert_to_tensor([1. for i in range(cutoff)])\n",
    "    expval = tf.einsum('ijkl,i,j,k,l->', tf.abs(psi)**2, n, eye, n, eye)\n",
    "    return expval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def end_network(state):\n",
    "    # Q: is it the same to do that vs mode=range(5)?\n",
    "    x = tf.stack([[tf.cast(state.mean_photon(mode=mode)[0], dtype=tf.float32)] for mode in modes_meas], axis=1)\n",
    "#     cov = tf.reshape(get_cov(state), (1,1))\n",
    "#     x = tf.concat([x, cov], axis=1)\n",
    "    out = x\n",
    "#     out = tf.layers.dense(out, 20, activation=tf.nn.relu)\n",
    "    out = tf.layers.dense(out, 20, activation=tf.nn.relu)\n",
    "    out = tf.layers.dense(out, 20, activation=tf.nn.relu)\n",
    "    out = tf.layers.dense(out, 1, activation=tf.nn.sigmoid)\n",
    "#     out = tf.layers.dense(out, 1, activation=None)\n",
    "    return tf.reshape(out, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine, q = sf.Engine(n_qumodes_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine:\n",
    "    state_preparation_network(q[:n_qumodes_psi], n_layers_sp, sp_params)\n",
    "#     MeasureFock(select=0) | q[1]\n",
    "    state_preparation_network(q[n_qumodes_psi:n_qumodes_psi*2], n_layers_sp, sp_params)\n",
    "    purification_network([q[0], q[2]], n_layers_pn, pn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run engine\n",
    "state = engine.run('tf', cutoff_dim=cutoff, eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# purity_output = tf.cast(state.quad_expectation(mode=0)[0], dtype=tf.float32)\n",
    "# purity_output = tf.cast(state.mean_photon(mode=0)[0], dtype=tf.float32)\n",
    "purity_output = end_network(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purity_mse(purity1, purity2):\n",
    "    return tf.reduce_mean(tf.square(purity1 - purity2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = purity_mse(purity_output, purity_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = tf.train.AdamOptimizer(learning_rate=lr_placeholder)\n",
    "min_cost = optimiser.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulation of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvs = tf.trainable_variables()\n",
    "accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        \n",
    "zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "gvs = optimiser.compute_gradients(cost, tvs)\n",
    "accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "train_step = optimiser.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_train_list = []\n",
    "cost_test_list = []\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost train after step    61:  0.0400227\n",
      "Cost test after step    61:  0.0528757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7685f5d573c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpurity_input\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_cost_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccum_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi_sample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi_sample\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size_pn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi_sample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_samples_train\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlr_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs = 30000\n",
    "lr = 50e-4\n",
    "batch_size_pn = 16\n",
    "n_iters_test = 10\n",
    "\n",
    "for i in range(i, nb_epochs+i):\n",
    "    cost_train = []\n",
    "    cost_test = [] \n",
    "    samples_idx = np.random.choice(n_samples_train, size=n_samples_train, replace=False)\n",
    "    \n",
    "    sess.run(zero_ops)\n",
    "    for i_sample in range(n_samples_train):\n",
    "        feed_dict_train = get_feed_dict(X_train[samples_idx[i_sample]])\n",
    "        feed_dict_train[purity_input] = Y_train[samples_idx[i_sample]]\n",
    "  \n",
    "        _, curr_cost_train = sess.run([accum_ops, cost], feed_dict=feed_dict_train)\n",
    "        if (i_sample != 0 and i_sample % batch_size_pn == 0) or i_sample == n_samples_train-1:\n",
    "            sess.run(train_step, feed_dict={lr_placeholder: lr})\n",
    "            sess.run(zero_ops)\n",
    "\n",
    "        cost_train.append(curr_cost_train) \n",
    "        \n",
    "    if i % n_iters_test == 0:\n",
    "        samples_idx = np.random.choice(n_samples_test, size=n_samples_test, replace=False)\n",
    "        for i_sample in range(n_samples_test):\n",
    "            feed_dict_test = get_feed_dict(X_test[samples_idx[i_sample]])\n",
    "            feed_dict_test[purity_input] = Y_test[samples_idx[i_sample]]\n",
    "            cost_test.append(sess.run([cost], feed_dict=feed_dict_test))\n",
    "        cost_test_list.append(np.mean(cost_test))\n",
    "        \n",
    "    cost_train_list.append(np.mean(cost_train))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Cost train after step {:5d}: {: .7f}'.format(i, cost_train_list[-1]))\n",
    "    print('Cost test after step {:5d}: {: .7f}'.format(i, cost_test_list[-1]))\n",
    "i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 10\n",
    "plt.rcParams['figure.figsize'] = (16,5)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(i)[start:], cost_train_list[start:], \n",
    "         label=\"Training learning curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0,i,n_iters_test)[start//n_iters_test:], cost_test_list[start//n_iters_test:], \n",
    "         label=\"Testing learning curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Result: {:0.6f}\".format(cost_train_list[-1]))\n",
    "purity_pred = []\n",
    "for j in range(n_samples_train):\n",
    "    feed_dict = get_feed_dict(X_train[j])\n",
    "    purity_pred.append(sess.run(purity_output, feed_dict=feed_dict))\n",
    "#     df = df.append([{\"Prediction\": purity_pred, \"Truth\": Y_train[j]}])\n",
    "# df.sort_values(\"Truth\")\n",
    "plt.scatter(Y_train, purity_pred, label=\"Train\")\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.xlabel(\"Truth\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Result: {:0.6f}\".format(cost_test_list[-1]))\n",
    "purity_pred = []\n",
    "for j in range(n_samples_test):\n",
    "    feed_dict = get_feed_dict(X_test[j])\n",
    "    purity_pred.append(sess.run(purity_output, feed_dict=feed_dict))\n",
    "#     df = df.append([{\"Prediction\": purity_pred, \"Truth\": Y_train[j]}])\n",
    "# df.sort_values(\"Truth\")\n",
    "plt.scatter(Y_test, purity_pred, label=\"Test\") \n",
    "plt.plot([0,1],[0,1])\n",
    "plt.xlabel(\"Truth\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig(\"experiments/cutoff-5/experiment_26/truth-predict.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_fct(rho, eps=1e-8):\n",
    "    eig = tf.linalg.eigvalsh(rho)\n",
    "    return - tf.real(tf.reduce_sum(eig * tf.log(eig + eps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = engine.run('tf', cutoff_dim=cutoff, eval=False, modes=[0])\n",
    "# rho_output = tf.reshape(tf.einsum('ijkl->ikjl', state.dm()), (9, 9))\n",
    "rho_output = state.dm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_entropies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples_idx = np.random.choice(n_samples_train, size=n_samples_train, replace=False)\n",
    "for i_sample in range(100,200):\n",
    "    clear_output(wait=True)\n",
    "    print(i_sample)\n",
    "    feed_dict = get_feed_dict(X_train[samples_idx[i_sample]])\n",
    "    list_entropies.append(sess.run(entropy_fct(rho_output), feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = plt.hist(list_entropies, density=True)\n",
    "plt.savefig(\"images/experiment_25/von-neumann-entropy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sf]",
   "language": "python",
   "name": "conda-env-sf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
